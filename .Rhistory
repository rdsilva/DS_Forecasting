# bibliotecas
library("tidyverse")
library("readr")
library("forecast")
library("tsibble")
library("tibbletime")
library("mice")
# importando os dados
weight <- read_csv("https://gist.githubusercontent.com/b-rodrigues/ea60679135f8dbed448ccf66a216811f/raw/18b469f3b0720f76ce5ee2715d0f9574b615f170/gistfile1.txt") %>%
as_tsibble()
# usando fill_na() para preencher as lacunas de dados não representadas no dataset
weight <- weight %>%
fill_na()
imp_weight <- mice(data = weight) %>%
mice::complete("long")
# analisando como ficaram os dados
head(imp_weight)
# recortando uma parte do dataset para treinar a ML
imp_weight_train <- imp_weight %>%
filter(Date >= "2016-07-11", Date <= "2018-05-31")
# reorganizando o dataset para manter apenas o necessário (removendo colunas e renomeando outras)
imp_weight_train <- imp_weight_train %>%
mutate(imputation = as.character(.imp)) %>%
select(-.id, -.imp) %>%
rename(date = Date) %>%
rename(weight = Poids)
# avaliando como ficaram os dados
ggplot(imp_weight_train, aes(date, weight, colour = imputation)) +
geom_line() +
theme(legend.position = "bottom")
# o grafico mostra muitas informações, mas é melhor suavizar as linhas, isto é feito utilizando rollify()
mean_roll_5 <- rollify(mean, window = 5)
mean_roll_10 <- rollify(mean, window = 10)
imp_weight_train <- imp_weight_train %>%
group_by(imputation) %>%
mutate(roll_5 = mean_roll_5(weight),
roll_10 = mean_roll_10(weight))
# reprocessei o dataset de treinamento, agora vamos ver como ficou no grafico
ggplot(imp_weight_train, aes(date, roll_5, colour = imputation)) +
geom_line() +
theme(legend.position = "bottom")
ggplot(imp_weight_train, aes(date, roll_10, colour = imputation)) +
geom_line() +
theme(legend.position = "bottom")
# especializando a função auto.arima() para trabalhar com data.frames além de listas
auto.arima.df <- function(data, y, ...){
y <- enquo(y)
yts <- data %>%
pull(!!y) %>%
as.ts()
auto.arima(yts, ...)
}
# o metodo acima converte o data.frame em uma serie temporal
# agora vamos agrupar os dados
nested_data <- imp_weight_train %>%
group_by(imputation) %>%
nest()
nested_data
# nesta estrutura agora é possível utilizar o metodo criado por nós e definir o Y da funÇão
models <- nested_data %>%
mutate(model = map(data, auto.arima.df, y = weight))
# avaliando como o modelo ficou
models
# agora a gente pode utilizar a função forecast() para criar as predições de peso, para este exemplo criamos predições de 24 dias... como o dataset foi filtrado até 31/05, esta predição deve prever o peso até o dia 24/06
forecasts <- models %>%
mutate(predictions = map(model, forecast, h = 24)) %>%
mutate(predictions = map(predictions, as_tibble)) %>%
pull(predictions)
forecasts
# o resultado é um conjunto de 5 predições, uma vez que entramos com um conjunto de 5 dados de pesos, assim sendo vamos fazer o merge do resultado para obtermos apenas um dataset resultado com as predições
forecasts <- map2(.x = forecasts, .y = as.character(seq(1, 5)),
~mutate(.x, id = .y)) %>%
bind_rows() %>%
select(-c(`Lo 80`, `Hi 80`))
colnames(forecasts) <- c("point_forecast", "low_95", "hi_95", "id")
forecasts
# ainda temos um conjunto de de 5 predições, apenas fizemos o merge dos datasets. Agora vamos fazer um reduce calculando as médias das previsões para cada um dos dias e assim termos apenas uma predição
weight_june <- modify(list_along(1:5), ~`<-`(., weight_june)) %>%
map2(.y = as.character(seq(1, 5)),
~mutate(.x, id = .y)) %>%
bind_rows()
weight_june <- imp_weight %>%
filter(Date >= "2018-06-01") %>%
select(-.id) %>%
group_by(Date) %>%
summarise(true_weight = mean(Poids)) %>%
rename(date = Date)
weight_june
# agora vamos repetir esse processo 5 vezes para então misturarmos o resultado com o dataset de previsão para assim compararmos no final
weight_june <- modify(list_along(1:5), ~`<-`(., weight_june)) %>%
map2(.y = as.character(seq(1, 5)),
~mutate(.x, id = .y)) %>%
bind_rows()
# vamos unir agora a media dos resultados com o previsto e analisar
forecasts <- bind_cols(weight_june, forecasts) %>%
select(-id1)
forecasts
# agora vamos ver o grafico final como fica
ggplot(forecasts, aes(x = date, colour = id)) +
geom_line(aes(y = true_weight), size = 2) +
geom_line(aes(y = hi_95)) +
geom_line(aes(y = low_95)) +
theme(legend.position = "bottom")
# selecionamos lá atrás apenas os resultados com 95% de probabilidade, ou seja, apenas os resultados que possuiam 95% de probabilidade de cair dentro do intervalo low_95 e hi_95.... como vocês podem ver no grafico, a média dos resultados oscila justamente entre esses valores, estando o hi_95 bem acima e o low_95 bem próximo das médias.
# infelizmente este teste foi feito em cima das anotações de uma pessoa que não conferiu se os resultados de fato acertaram e qual a margem de acerto, contrudo vc pode revisar o artigo original no link <https://www.r-bloggers.com/forecasting-my-weight-with-r/amp/>
View(forecasts)
View(forecasts)
